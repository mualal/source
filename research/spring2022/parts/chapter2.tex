\chapter{Обучение моделей} \label{ch2}
Во второй главе на основе рассматриваемых датасетов обучены модели машинного обучения и проведено сравнение диаграмм размаха ошибок построенных моделей с аналогичными диаграммами из работы \cite{muravtsev:metamodel}. Код для обучения всех обсуждаемых моделей представлен в приложении 1.

\section{Линейная регрессия} \label{ch1:sec1}

Модель обучается при выполнении функции linear\_regression класса ReservoirMetamodel (см. приложение 1).

Из диаграмм размаха ошибок (рис. \ref{fig:lin-reg-1}) видим, что в случае линейной регрессии на некоторых кейсах ошибки достигают высоких значений. Это связано с ограниченной гибкостью линейной модели и небольшим количеством кейсов в области входных параметров, которой соответствуют низкие значения дебитов (менее 5 $\text{м}^3/\text{сут}$ за каждый месяц в течение всех рассматриваемых пяти лет).

\begin{figure}[H] 
	\center
	\includegraphics[width=\textwidth]{images/linear_regression_test_errors_boxplot_scenario1}
	\caption{Диаграмма ошибок прогноза линейной регрессии (сценарий 1)} 
	\label{fig:lin-reg-1}
\end{figure}

Прогнозы линейной регрессии в случае второго сценария разработки (рис. \ref{fig:lin-reg-2}) значительно хуже первого сценария (что видно из гораздо более длинных усов на диаграммах размаха ошибок в 5-25 месяцы). Во втором сценарии от аппроксимации требуется ещё большая гибкость (так как изменяется режим разработки), что не может быть обеспечено линейной регрессией.

\begin{figure}[H] 
	\center
	\includegraphics[width=\textwidth]{images/linear_regression_test_errors_boxplot_scenario2}
	\caption{Диаграмма ошибок прогноза линейной регрессии (сценарий 2)} 
	\label{fig:lin-reg-2}
\end{figure}


\section{Регрессия ближайших соседей} \label{ch1:sec2}

Модель обучается при выполнении функции neigh\_regression класса ReservoirMetamodel (см. приложение 1).

Видим, что прогнозы регрессии ближайших соседей (рис. \ref{fig:neighs-reg-1}), чем прогнозы линейной регрессии. Но по-прежнему есть высокие значения ошибок вследствие несбалансированности данных (количество примеров с низкими значениями выходных дебитов в обучающей выборке существенно меньше, чем количество примеров со средними или высокими значениями дебитов).  

\begin{figure}[H] 
	\center
	\includegraphics[width=\textwidth]{images/nearest_neighs_approximation_test_errors_boxplot_scenario1}
	\caption{Диаграмма ошибок прогноза регрессии ближайших соседей (сценарий 1)} 
	\label{fig:neighs-reg-1}
\end{figure}

Заметное улучшение точности прогноза (по сравнению с линейной регрессией) наблюдается для многих кейсов второго сценария (рис. \ref{fig:neighs-reg-2})

\begin{figure}[H] 
	\center
	\includegraphics[width=\textwidth]{images/nearest_neighs_approximation_test_errors_boxplot_scenario2}
	\caption{Диаграмма ошибок прогноза регрессии ближайших соседей (сценарий 2)} 
	\label{fig:neighs-reg-2}
\end{figure}


\section{Регрессия на основе метода опорных векторов} \label{ch1:sec3}

Модель обучается при выполнении функции svm\_regression класса ReservoirMetamodel (см. приложение 1).

Видим, что регрессия опорных векторов в первом сценарии даёт гораздо меньшие ошибки (рис. \ref{fig:svm-reg-1}), чем линейная регрессия и регрессия ближайших соседей.

\begin{figure}[H] 
	\center
	\includegraphics[width=\textwidth]{images/svm_approximation_test_errors_boxplot_scenario1}
	\caption{Диаграмма ошибок прогноза регрессии опорных векторов (сценарий 1)} 
	\label{fig:svm-reg-1}
\end{figure}

Во втором сценарии на некоторых кейсах точность регрессии на основе опорных векторов лучше линейной и ближайших соседей, но по-прежнему есть кейсы с существенными ошибками прогноза (рис. \ref{fig:svm-reg-2}).

\begin{figure}[H] 
	\center
	\includegraphics[width=\textwidth]{images/svm_approximation_test_errors_boxplot_scenario2}
	\caption{Диаграмма ошибок прогноза регрессии опорных векторов (сценарий 2)} 
	\label{fig:svm-reg-2}
\end{figure}

\section{Чрезвычайно рандомизированные деревья} \label{ch1:sec4}

Модель обучается при выполнении функции extra\_trees\_regression класса ReservoirMetamodel (см. приложение 1).

Из диаграмм размаха ошибок (рис. \ref{fig:extra-trees-reg-1} и рис. \ref{fig:extra-trees-reg-2}) видим, что регрессия на основе чрезвычайно рандомизированных деревьев может быть полезна при составлении прогноза для данных, подобных данным второго сценария разработки, так как количество кейсов с высокими значениями ошибок заметно сократилось и сами значения этих ошибок снизились.

\begin{figure}[H] 
	\center
	\includegraphics[width=\textwidth]{images/extra_trees_regression_test_errors_boxplot_scenario1}
	\caption{Диаграмма ошибок прогноза регрессии на основе чрезвычайно рандомизированных деревьев (сценарий 1)} 
	\label{fig:extra-trees-reg-1}
\end{figure}

\begin{figure}[H] 
	\center
	\includegraphics[width=\textwidth]{images/extra_trees_regression_test_errors_boxplot_scenario2}
	\caption{Диаграмма ошибок прогноза регрессии на основе чрезвычайно рандомизированных деревьев (сценарий 2)} 
	\label{fig:extra-trees-reg-2}
\end{figure}

\section{Расширенные с помощью базисных функций линейные модели} \label{ch1:sec5}

Модель обучается при выполнении функции manual\_approximation класса ReservoirMetamodel (см. приложение 1).

Из диаграмм размаха ошибок (рис. \ref{fig:manual-reg-1} и рис. \ref{fig:manual-reg-2}) видим, что данной тип аппроксимации лучше линейной регрессии, но хуже остальных рассмотренных ранее аппроксимаций.

\begin{figure}[H] 
	\center
	\includegraphics[width=\textwidth]{images/manual_approximation_test_errors_boxplot_scenario1}
	\caption{Диаграмма ошибок прогноза расширенных линейных моделей (сценарий 1)} 
	\label{fig:manual-reg-1}
\end{figure}

\begin{figure}[H] 
	\center
	\includegraphics[width=\textwidth]{images/manual_approximation_test_errors_boxplot_scenario2}
	\caption{Диаграмма ошибок прогноза расширенных линейных моделей (сценарий 2)} 
	\label{fig:manual-reg-2}
\end{figure}


\section{Выводы} \label{ch1:conclusion}

В текущей главе были построены аппроксимации разными методами машинного обучения. Наиболее точными оказались регрессия на основе метода опорных векторов и регрессия на основе чрезвычайно рандомизированных деревьев. Однако точность их прогноза не значительно лучше (а для некоторых кейсов хуже) точности прогноза нейронных сетей и градиентного бустинга на основе деревьев регрессии из работы \cite{muravtsev:metamodel}.




